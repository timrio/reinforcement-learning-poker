{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc20b17-4135-45b6-a06c-24192262dc06",
   "metadata": {},
   "source": [
    "---\n",
    "Vérifier qu'on n'est pas en 3.10.2 (sinon PyTorch ne marchera pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c183a798-d4cf-4255-a655-49a421fd46d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e856d00-aebe-4c1f-b801-b6fcbc5a0301",
   "metadata": {},
   "source": [
    "---\n",
    "Imports - notemment de clubs_gym (https://github.com/fschlatt/clubs_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62db73dc-8949-48e8-b793-44e03d980345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import clubs_gym\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b50f010-05d0-427b-b5ec-6496ceb7aed0",
   "metadata": {},
   "source": [
    "---\n",
    "Liste des environnements disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9ce39a-be22-4143-922f-2237f9c0a7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeducTwoPlayer-v0',\n",
       " 'KuhnTwoPlayer-v0',\n",
       " 'KuhnThreePlayer-v0',\n",
       " 'LimitHoldemTwoPlayer-v0',\n",
       " 'LimitHoldemSixPlayer-v0',\n",
       " 'LimitHoldemNinePlayer-v0',\n",
       " 'NoLimitHoldemTwoPlayer-v0',\n",
       " 'NoLimitHoldemSixPlayer-v0',\n",
       " 'NoLimitHoldemNinePlayer-v0',\n",
       " 'NoLimitHoldemBbAnteNinePlayer-v0',\n",
       " 'PotLimitOmahaTwoPlayer-v0',\n",
       " 'PotLimitOmahaSixPlayer-v0',\n",
       " 'PotLimitOmahaNinePlayer-v0',\n",
       " 'ShortDeckTwoPlayer-v0',\n",
       " 'ShortDeckSixPlayer-v0',\n",
       " 'ShortDeckNinePlayer-v0']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clubs_gym.ENVS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537f17d-98cb-492b-a495-dda6c21db7a2",
   "metadata": {},
   "source": [
    "Ne nous intéressera que `NoLimitHoldemTwoPlayer-v0` et `NoLimitHoldemSixPlayer-v0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4c9a9-9288-4f66-918e-ddb64771bec1",
   "metadata": {},
   "source": [
    "---\n",
    "Ouvrons `NoLimitHoldemTwoPlayer-v0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f85fcfc-d342-46e5-9167-b649244043fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_str = \"NoLimitHoldemTwoPlayer-v0\"\n",
    "num_players = 2  # heads-up\n",
    "num_streets = 4  # texas hold'em\n",
    "blinds = [1, 2]  # as on the tables on which we used to play @Jean\n",
    "antes = 0  # a bit weird to have antes in a heads-up I reckon (single ints are expanded to the number of players so could've inputted a list)\n",
    "raise_sizes = ['inf', 'inf', 'inf', 'inf']  # yes the documentation is wrong, 'inf' should be used and not float('inf')\n",
    "num_raises = 'inf'  # max number of bets for each street* (including preflop)\n",
    "num_suits = 4  # number of suits to use in deck (obviously 4 otherwise I mean it's weird)\n",
    "num_ranks = 13  # same, obviously 13 (A, 2, 3, 4, 5, 6, 7, 8, 9, T, J, Q, K)\n",
    "num_hole_cards = 2  # **\n",
    "mandatory_num_hole_cards = 0  # you can use the fives on the board and it will end up being a draw if your enemy does it too\n",
    "num_community_cards = [0, 3, 1, 1]  # preflop, flop, turn, river\n",
    "start_stack = 100  # as on the tables on which we used to play @Jean (actually it was any integer between 80 and 200)\n",
    "n_cards_for_hand = 5  # texas hold'em\n",
    "order = ['sf', 'fk', 'fh', 'fl', 'st', 'tk', 'tp', 'pa', 'hc']  # most likely optional, but just to make sure we're working with the right order\n",
    "\n",
    "config_dict = {'num_players': num_players,\n",
    "               'num_streets': num_streets,\n",
    "               'blinds': blinds,\n",
    "               'antes': antes,\n",
    "               'raise_sizes': raise_sizes,\n",
    "               'num_raises': num_raises,\n",
    "               'num_suits': num_suits,\n",
    "               'num_ranks': num_ranks,\n",
    "               'num_hole_cards': num_hole_cards,\n",
    "               'mandatory_num_hole_cards': mandatory_num_hole_cards,\n",
    "               'num_community_cards': num_community_cards,\n",
    "               'start_stack': start_stack,\n",
    "               'num_cards_for_hand': n_cards_for_hand,\n",
    "               'order': order}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7f179-4f96-4f4d-b7a7-d512405f139b",
   "metadata": {},
   "source": [
    "---\n",
    "Un peu de vocabulaire pour les zguegs (là où y avait des * au-dessus):\n",
    "- \\* A card that’s dealt in a particular betting round, in many poker variants, is called a **street**. For example, in Texas Hold’em and Omaha, the community cards are referred to as the flop, turn and river, with the turn and river sometimes referred to as Fourth Street and Fifth Street.\n",
    "- ** The term **hole cards' in poker signals that the cards are private cards that should only be viewed by the player. The dealer deals hole cards face down and players should ensure that the value of those cards remains secret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16101591-27cf-4557-a5d0-461b714bb1ba",
   "metadata": {},
   "source": [
    "---\n",
    "`obs` est illisible donc on fait une fonction `print_obs` pour avoir des jolis prints sur ce qu'il se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77be690f-5596-499c-a36e-9d009e648a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obs(obs):\n",
    "    \"\"\"\n",
    "    Fancy print of stats for the clubs gym poker gym.\n",
    "    All Cards displayed (on voit les cartes de tout le monde quoi)\n",
    "    \n",
    "    param: obs: le premier chose renvoyé par env.step\n",
    "    return: nada\n",
    "    \"\"\"\n",
    "    for _ in range(5):\n",
    "        print('---')\n",
    "    print('------------------- Players\\' stacks -------------------')\n",
    "    print(f\"player_0: {obs['stacks'][0]}\\n\" + \\\n",
    "          f\"player_1: {obs['stacks'][1]}\")\n",
    "    print('------------------- Game Stats -------------------')\n",
    "    print(f'community_cards: {obs[\"community_cards\"]}')\n",
    "    print(f'Dealer/Button: {obs[\"button\"] % 2}')\n",
    "    print(f'Pot: {obs[\"pot\"]}')\n",
    "    print(f'Commits: player_0: {obs[\"street_commits\"][0]} |||  player_1: {obs[\"street_commits\"][1]}')\n",
    "\n",
    "    if not obs['action'] == -1:\n",
    "        print(f\"\\n---------------- player {obs['action']}'s turn ----------------\")\n",
    "        print(f'hole_cards: {obs[\"hole_cards\"]}')\n",
    "        print(f'call: {obs[\"call\"]}, min_raise: {obs[\"min_raise\"]}, max_raise: {obs[\"max_raise\"]}', end='\\n\\n')\n",
    "    else:\n",
    "        print('\\n[INFO] - End of the Game.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b26875-7c1a-4eaa-91fd-7c6f4fa11eb2",
   "metadata": {},
   "source": [
    "---\n",
    "Main\n",
    "\n",
    "Dans `env.step`, mettre un integer qui correspond à ce que vous voulez miser. \n",
    "- Si la mise est inférieure à la mise minimum, vous vous couchez. \n",
    "- Si la mise est supérieure à la mise maximum (en no limit, ça veut dire vous voulez miser plus que ce que vous détenez) alors all in.\n",
    "\n",
    "Le truc ci-dessous vous fait changer de joueur pré/post flop - désolé. This is because *in Heads Up poker, the button acts first preflop and last postflop*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25490bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clubs_gym.agent.base import BaseAgent\n",
    "\n",
    "class RandomAllInFold(BaseAgent):\n",
    "    '''\n",
    "    this agent bets everyting or folds (50/50 chance)\n",
    "    '''\n",
    "    def __init__(self, player_id, seed = 42):\n",
    "        self.rand_generator = np.random.RandomState(seed)\n",
    "        self.player_id = player_id\n",
    "\n",
    "    def act(self, info_dict):\n",
    "        available_chips = info_dict['stacks'][self.player_id]\n",
    "        draw = np.random.random()\n",
    "        if draw >= 0.5:\n",
    "            action = 1 \n",
    "        else:\n",
    "            action = 0\n",
    "\n",
    "        ## outpu  \n",
    "        if action == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            return(available_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d599005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clubs_gym.agent.base import BaseAgent\n",
    "class HumanRandomAllInFold(BaseAgent):\n",
    "    \"\"\"\n",
    "    only two possible actions, all in or folds\n",
    "    \"\"\"\n",
    "    def __init__(self, player_id, seed = 42):\n",
    "        self.player_id = player_id\n",
    "\n",
    "    def act(self, info_dict):\n",
    "        available_chips = info_dict['stacks'][self.player_id]\n",
    "        action = -1\n",
    "        while action != 0 and action != 1:\n",
    "            action = int(input())\n",
    "        if action == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            return(available_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d850150",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllInFoldQLearningAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    actions:\n",
    "        - 0: folds\n",
    "        - 1: all-in\n",
    "    \"\"\"\n",
    "    def __init__(self, player_id, agent_init_info):\n",
    "        self.player_id = player_id\n",
    "\n",
    "        self.state_size = agent_init_info[\"state_size\"]\n",
    "        self.num_actions = agent_init_info[\"num_actions\"]\n",
    "        self.epsilon = agent_init_info[\"epsilon\"]\n",
    "        self.step_size = agent_init_info[\"step_size\"]\n",
    "        self.discount = agent_init_info[\"discount\"]\n",
    "        self.rand_generator = np.random.RandomState(agent_init_info[\"seed\"])\n",
    "        self.step = 0\n",
    "        self.has_made_a_decision = False \n",
    "        self.q = {}\n",
    "\n",
    "        \n",
    "    def agent_start(self, state):\n",
    "        self.has_made_a_decision = True\n",
    "\n",
    "        tuple_representing_state = (str(state[0]), str(state[1]))\n",
    "        current_q = self.q.setdefault(tuple_representing_state, [0]*self.num_actions)\n",
    "        if self.rand_generator.rand() < self.epsilon:\n",
    "            action = self.rand_generator.randint(self.num_actions) # random action selection\n",
    "        else:\n",
    "            action = self.argmax(current_q) # greedy action selection\n",
    "        self.prev_state = tuple_representing_state\n",
    "        self.prev_action = action\n",
    "        return action\n",
    "    \n",
    "    def agent_step(self, reward, state):\n",
    "        # Choose action using epsilon greedy.\n",
    "        tuple_representing_state = (str(state[0]), str(state[1]))\n",
    "        current_q = self.q.setdefault(tuple_representing_state, [0]*self.num_actions)\n",
    "        if self.rand_generator.rand() < self.epsilon:\n",
    "            action = self.rand_generator.randint(self.num_actions)\n",
    "        else:\n",
    "            action = self.argmax(current_q)\n",
    "        \n",
    "        previous_values_list = self.q[self.prev_state]\n",
    "        previous_values_list[self.prev_action] += self.step_size*(reward + self.discount*np.max(self.q[tuple_representing_state]) - self.q[self.prev_state][self.prev_action])\n",
    "        self.q[self.prev_state] = previous_values_list\n",
    "        \n",
    "        self.prev_state = tuple_representing_state\n",
    "        self.prev_action = action\n",
    "        return action\n",
    "    \n",
    "    def agent_end(self, reward):\n",
    "        if self.has_made_a_decision:\n",
    "            previous_values_list = self.q[self.prev_state]\n",
    "            previous_values_list[self.prev_action] += self.step_size*(reward - self.q[self.prev_state][self.prev_action])\n",
    "            self.q[self.prev_state] = previous_values_list\n",
    "\n",
    "\n",
    "\n",
    "    def act(self, info_dict):\n",
    "        reward = info_dict['rewards'][self.player_id]\n",
    "        done = info_dict['done']\n",
    "        state = info_dict['state']\n",
    "        number_of_chips = info_dict['stacks'][self.player_id]\n",
    "        \n",
    "\n",
    "        if self.step == 0:\n",
    "            action = self.agent_start(state)\n",
    "\n",
    "        elif not done:\n",
    "            action = self.agent_step(reward, state)\n",
    "\n",
    "        elif done:\n",
    "            print(\"weird\")\n",
    "            exit()\n",
    "\n",
    "        self.step += 1\n",
    "        if action == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            return(number_of_chips)\n",
    "        \n",
    "    def argmax(self, q_values):\n",
    "        top = float(\"-inf\")\n",
    "        ties = []\n",
    "\n",
    "        for i in range(len(q_values)):\n",
    "            if q_values[i] > top:\n",
    "                top = q_values[i]\n",
    "                ties = []\n",
    "\n",
    "            if q_values[i] == top:\n",
    "                ties.append(i)\n",
    "\n",
    "        return self.rand_generator.choice(ties)\n",
    "\n",
    "    def set_epsilon(self, value):\n",
    "        self.epsilon = value\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        obj = pickle.load(open(path,'wb'))\n",
    "        return(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d2f41cb-0b18-4a29-96d3-76947b43d486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\RL\\reinforcement-learning-poker\\venv\\lib\\site-packages\\gym\\envs\\registration.py:595: UserWarning: \u001b[33mWARN: Overriding environment NoLimitHoldemTwoPlayer-v0\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {id}\")\n",
      "100%|██████████| 100000/100000 [00:16<00:00, 6110.86it/s]\n"
     ]
    }
   ],
   "source": [
    "clubs_gym.envs.register({env_str: config_dict})\n",
    "env = gym.make(env_str)\n",
    "q_learning_agent_info = {\"state_size\":2, \"num_actions\": 2 , \"epsilon\": 0.1, \"step_size\": 0.1, \"discount\": 1.0, \"seed\": 0}\n",
    "agents = [AllInFoldQLearningAgent(0, q_learning_agent_info), RandomAllInFold(1)]\n",
    "env.register_agents(agents)\n",
    "\n",
    "# Start the game\n",
    "for episodes in tqdm(range(100000), position = 0):\n",
    "    obs = env.reset(reset_stacks = True)\n",
    "\n",
    "    # create a dict containing all necessary info for q learning agent\n",
    "    info_dict = {}\n",
    "    if obs['action'] != -1:\n",
    "        done_agent = False\n",
    "    else:\n",
    "        done_agent = True\n",
    "    info_dict['rewards'] = [0,0]\n",
    "    info_dict['done'] = done_agent\n",
    "    info_dict['state'] = obs['hole_cards']\n",
    "    info_dict['stacks'] = obs['stacks']\n",
    "\n",
    "    while True:\n",
    "        bet = env.act(info_dict)\n",
    "        obs, rewards, done, info = env.step(bet)  \n",
    "        # updata dict\n",
    "        info_dict = {}\n",
    "        if obs['action'] != -1:\n",
    "            done_agent = False\n",
    "        else:\n",
    "            done_agent = True\n",
    "        info_dict['rewards'] = rewards\n",
    "        info_dict['done'] = done_agent\n",
    "        info_dict['state'] = obs['hole_cards']\n",
    "        info_dict['stacks'] = obs['stacks']\n",
    "\n",
    "\n",
    "        # print_obs(obs)\n",
    "        if all(done):\n",
    "            agents[0].agent_end(rewards[0])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46bfd055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9789140154906946, 33.914494116080384]\n",
      "[0.008594183914281892, -9.0]\n"
     ]
    }
   ],
   "source": [
    "print(agents[0].q['A♥', 'A♦'])\n",
    "print(agents[0].q['2♥', '7♦'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcec69c699ccacfedc0ca836cb12e805212fde22d8796542a43a04124dd506b9"
  },
  "kernelspec": {
   "display_name": "PokerKernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
