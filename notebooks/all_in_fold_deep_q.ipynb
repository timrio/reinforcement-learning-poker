{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc20b17-4135-45b6-a06c-24192262dc06",
   "metadata": {},
   "source": [
    "---\n",
    "Vérifier qu'on n'est pas en 3.10.2 (sinon PyTorch ne marchera pas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc20b17-4135-45b6-a06c-24192262dc06",
   "metadata": {},
   "source": [
    "---\n",
    "Vérifier qu'on n'est pas en 3.10.2 (sinon PyTorch ne marchera pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c183a798-d4cf-4255-a655-49a421fd46d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e856d00-aebe-4c1f-b801-b6fcbc5a0301",
   "metadata": {},
   "source": [
    "---\n",
    "Imports - notemment de clubs_gym (https://github.com/fschlatt/clubs_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62db73dc-8949-48e8-b793-44e03d980345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import clubs_gym\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b50f010-05d0-427b-b5ec-6496ceb7aed0",
   "metadata": {},
   "source": [
    "---\n",
    "Liste des environnements disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0e9ce39a-be22-4143-922f-2237f9c0a7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeducTwoPlayer-v0',\n",
       " 'KuhnTwoPlayer-v0',\n",
       " 'KuhnThreePlayer-v0',\n",
       " 'LimitHoldemTwoPlayer-v0',\n",
       " 'LimitHoldemSixPlayer-v0',\n",
       " 'LimitHoldemNinePlayer-v0',\n",
       " 'NoLimitHoldemTwoPlayer-v0',\n",
       " 'NoLimitHoldemSixPlayer-v0',\n",
       " 'NoLimitHoldemNinePlayer-v0',\n",
       " 'NoLimitHoldemBbAnteNinePlayer-v0',\n",
       " 'PotLimitOmahaTwoPlayer-v0',\n",
       " 'PotLimitOmahaSixPlayer-v0',\n",
       " 'PotLimitOmahaNinePlayer-v0',\n",
       " 'ShortDeckTwoPlayer-v0',\n",
       " 'ShortDeckSixPlayer-v0',\n",
       " 'ShortDeckNinePlayer-v0']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clubs_gym.ENVS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537f17d-98cb-492b-a495-dda6c21db7a2",
   "metadata": {},
   "source": [
    "Ne nous intéressera que `NoLimitHoldemTwoPlayer-v0` et `NoLimitHoldemSixPlayer-v0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4c9a9-9288-4f66-918e-ddb64771bec1",
   "metadata": {},
   "source": [
    "---\n",
    "Ouvrons `NoLimitHoldemTwoPlayer-v0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4f85fcfc-d342-46e5-9167-b649244043fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_str = \"NoLimitHoldemTwoPlayer-v0\"\n",
    "num_players = 2  # heads-up\n",
    "num_streets = 4  # texas hold'em\n",
    "blinds = [1, 2]  # as on the tables on which we used to play @Jean\n",
    "antes = 0  # a bit weird to have antes in a heads-up I reckon (single ints are expanded to the number of players so could've inputted a list)\n",
    "raise_sizes = ['inf', 'inf', 'inf', 'inf']  # yes the documentation is wrong, 'inf' should be used and not float('inf')\n",
    "num_raises = 'inf'  # max number of bets for each street* (including preflop)\n",
    "num_suits = 4  # number of suits to use in deck (obviously 4 otherwise I mean it's weird)\n",
    "num_ranks = 13  # same, obviously 13 (A, 2, 3, 4, 5, 6, 7, 8, 9, T, J, Q, K)\n",
    "num_hole_cards = 2  # **\n",
    "mandatory_num_hole_cards = 0  # you can use the fives on the board and it will end up being a draw if your enemy does it too\n",
    "num_community_cards = [0, 3, 1, 1]  # preflop, flop, turn, river\n",
    "start_stack = 100  # as on the tables on which we used to play @Jean (actually it was any integer between 80 and 200)\n",
    "n_cards_for_hand = 5  # texas hold'em\n",
    "order = ['sf', 'fk', 'fh', 'fl', 'st', 'tk', 'tp', 'pa', 'hc']  # most likely optional, but just to make sure we're working with the right order\n",
    "\n",
    "config_dict = {'num_players': num_players,\n",
    "               'num_streets': num_streets,\n",
    "               'blinds': blinds,\n",
    "               'antes': antes,\n",
    "               'raise_sizes': raise_sizes,\n",
    "               'num_raises': num_raises,\n",
    "               'num_suits': num_suits,\n",
    "               'num_ranks': num_ranks,\n",
    "               'num_hole_cards': num_hole_cards,\n",
    "               'mandatory_num_hole_cards': mandatory_num_hole_cards,\n",
    "               'num_community_cards': num_community_cards,\n",
    "               'start_stack': start_stack,\n",
    "               'num_cards_for_hand': n_cards_for_hand,\n",
    "               'order': order}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f7f179-4f96-4f4d-b7a7-d512405f139b",
   "metadata": {},
   "source": [
    "---\n",
    "Un peu de vocabulaire pour les zguegs (là où y avait des * au-dessus):\n",
    "- \\* A card that’s dealt in a particular betting round, in many poker variants, is called a **street**. For example, in Texas Hold’em and Omaha, the community cards are referred to as the flop, turn and river, with the turn and river sometimes referred to as Fourth Street and Fifth Street.\n",
    "- ** The term **hole cards' in poker signals that the cards are private cards that should only be viewed by the player. The dealer deals hole cards face down and players should ensure that the value of those cards remains secret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16101591-27cf-4557-a5d0-461b714bb1ba",
   "metadata": {},
   "source": [
    "---\n",
    "`obs` est illisible donc on fait une fonction `print_obs` pour avoir des jolis prints sur ce qu'il se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "77be690f-5596-499c-a36e-9d009e648a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_obs(obs):\n",
    "    \"\"\"\n",
    "    Fancy print of stats for the clubs gym poker gym.\n",
    "    All Cards displayed (on voit les cartes de tout le monde quoi)\n",
    "    \n",
    "    param: obs: le premier chose renvoyé par env.step\n",
    "    return: nada\n",
    "    \"\"\"\n",
    "    for _ in range(5):\n",
    "        print('---')\n",
    "    print('------------------- Players\\' stacks -------------------')\n",
    "    print(f\"player_0: {obs['stacks'][0]}\\n\" + \\\n",
    "          f\"player_1: {obs['stacks'][1]}\")\n",
    "    print('------------------- Game Stats -------------------')\n",
    "    print(f'community_cards: {obs[\"community_cards\"]}')\n",
    "    print(f'Dealer/Button: {obs[\"button\"] % 2}')\n",
    "    print(f'Pot: {obs[\"pot\"]}')\n",
    "    print(f'Commits: player_0: {obs[\"street_commits\"][0]} |||  player_1: {obs[\"street_commits\"][1]}')\n",
    "\n",
    "    if not obs['action'] == -1:\n",
    "        print(f\"\\n---------------- player {obs['action']}'s turn ----------------\")\n",
    "        print(f'hole_cards: {obs[\"hole_cards\"]}')\n",
    "        print(f'call: {obs[\"call\"]}, min_raise: {obs[\"min_raise\"]}, max_raise: {obs[\"max_raise\"]}', end='\\n\\n')\n",
    "    else:\n",
    "        print('\\n[INFO] - End of the Game.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b26875-7c1a-4eaa-91fd-7c6f4fa11eb2",
   "metadata": {},
   "source": [
    "---\n",
    "Main\n",
    "\n",
    "Dans `env.step`, mettre un integer qui correspond à ce que vous voulez miser. \n",
    "- Si la mise est inférieure à la mise minimum, vous vous couchez. \n",
    "- Si la mise est supérieure à la mise maximum (en no limit, ça veut dire vous voulez miser plus que ce que vous détenez) alors all in.\n",
    "\n",
    "Le truc ci-dessous vous fait changer de joueur pré/post flop - désolé. This is because *in Heads Up poker, the button acts first preflop and last postflop*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "25490bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clubs_gym.agent.base import BaseAgent\n",
    "\n",
    "class RandomAllInFold(BaseAgent):\n",
    "    '''\n",
    "    this agent bets everyting or folds (50/50 chance)\n",
    "    '''\n",
    "    def __init__(self, player_id, seed = 42):\n",
    "        self.rand_generator = np.random.RandomState(seed)\n",
    "        self.player_id = player_id\n",
    "\n",
    "    def act(self, info_dict):\n",
    "        available_chips = info_dict['stacks'][self.player_id]\n",
    "        draw = np.random.random()\n",
    "        if draw >= 0.5:\n",
    "            action = 1 \n",
    "        else:\n",
    "            action = 0\n",
    "\n",
    "        ## outpu  \n",
    "        if action == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            return(available_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d599005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clubs_gym.agent.base import BaseAgent\n",
    "class HumanRandomAllInFold(BaseAgent):\n",
    "    \"\"\"\n",
    "    only two possible actions, all in or folds\n",
    "    \"\"\"\n",
    "    def __init__(self, player_id, seed = 42):\n",
    "        self.player_id = player_id\n",
    "\n",
    "    def act(self, info_dict):\n",
    "        available_chips = info_dict['stacks'][self.player_id]\n",
    "        action = -1\n",
    "        while action != 0 and action != 1:\n",
    "            action = int(input())\n",
    "        if action == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            return(available_chips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1d850150",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AllInFoldQLearningAgent(BaseAgent):\n",
    "    \"\"\"\n",
    "    actions:\n",
    "        - 0: folds\n",
    "        - 1: all-in\n",
    "    \"\"\"\n",
    "    def __init__(self, player_id, agent_init_info):\n",
    "        self.player_id = player_id\n",
    "\n",
    "        self.state_size = agent_init_info[\"state_size\"]\n",
    "        self.num_actions = agent_init_info[\"num_actions\"]\n",
    "        self.epsilon = agent_init_info[\"epsilon\"]\n",
    "        self.step_size = agent_init_info[\"step_size\"]\n",
    "        self.discount = agent_init_info[\"discount\"]\n",
    "        self.rand_generator = np.random.RandomState(agent_init_info[\"seed\"])\n",
    "        self.step = 0\n",
    "        self.has_made_a_decision = False \n",
    "        self.q = {}\n",
    "\n",
    "        \n",
    "    def agent_start(self, state):\n",
    "        self.has_made_a_decision = True\n",
    "\n",
    "        tuple_representing_state = (str(state[0]), str(state[1]))\n",
    "        current_q = self.q.setdefault(tuple_representing_state, [0]*self.num_actions)\n",
    "        if self.rand_generator.rand() < self.epsilon:\n",
    "            action = self.rand_generator.randint(self.num_actions) # random action selection\n",
    "        else:\n",
    "            action = self.argmax(current_q) # greedy action selection\n",
    "        self.prev_state = tuple_representing_state\n",
    "        self.prev_action = action\n",
    "        return action\n",
    "    \n",
    "    def agent_step(self, reward, state):\n",
    "        # Choose action using epsilon greedy.\n",
    "        tuple_representing_state = (str(state[0]), str(state[1]))\n",
    "        current_q = self.q.setdefault(tuple_representing_state, [0]*self.num_actions)\n",
    "        if self.rand_generator.rand() < self.epsilon:\n",
    "            action = self.rand_generator.randint(self.num_actions)\n",
    "        else:\n",
    "            action = self.argmax(current_q)\n",
    "        \n",
    "        previous_values_list = self.q[self.prev_state]\n",
    "        previous_values_list[self.prev_action] += self.step_size*(reward + self.discount*np.max(self.q[tuple_representing_state]) - self.q[self.prev_state][self.prev_action])\n",
    "        self.q[self.prev_state] = previous_values_list\n",
    "        \n",
    "        self.prev_state = tuple_representing_state\n",
    "        self.prev_action = action\n",
    "        return action\n",
    "    \n",
    "    def agent_end(self, reward):\n",
    "        if self.has_made_a_decision:\n",
    "            previous_values_list = self.q[self.prev_state]\n",
    "            previous_values_list[self.prev_action] += self.step_size*(reward - self.q[self.prev_state][self.prev_action])\n",
    "            self.q[self.prev_state] = previous_values_list\n",
    "\n",
    "\n",
    "\n",
    "    def act(self, info_dict):\n",
    "        reward = info_dict['rewards'][self.player_id]\n",
    "        done = info_dict['done']\n",
    "        state = info_dict['state']\n",
    "        number_of_chips = info_dict['stacks'][self.player_id]\n",
    "        \n",
    "\n",
    "        if self.step == 0:\n",
    "            action = self.agent_start(state)\n",
    "\n",
    "        elif not done:\n",
    "            action = self.agent_step(reward, state)\n",
    "\n",
    "        elif done:\n",
    "            print(\"weird\")\n",
    "            exit()\n",
    "\n",
    "        self.step += 1\n",
    "        if action == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            return(number_of_chips)\n",
    "        \n",
    "    def argmax(self, q_values):\n",
    "        top = float(\"-inf\")\n",
    "        ties = []\n",
    "\n",
    "        for i in range(len(q_values)):\n",
    "            if q_values[i] > top:\n",
    "                top = q_values[i]\n",
    "                ties = []\n",
    "\n",
    "            if q_values[i] == top:\n",
    "                ties.append(i)\n",
    "\n",
    "        return self.rand_generator.choice(ties)\n",
    "\n",
    "    def set_epsilon(self, value):\n",
    "        self.epsilon = value\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        obj = pickle.load(open(path,'wb'))\n",
    "        return(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5bb3acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_shape = 52, n_actions = 2):\n",
    "        super(NN, self).__init__()\n",
    "            \n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(input_shape, input_shape),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_shape,  n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.dense(x)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2f4cce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(BaseAgent):\n",
    "\n",
    "    def __init__(self, player_id, agent_init_info, batch_size = 100, max_memory_size = 1000000):\n",
    "        self.player_id = player_id\n",
    "\n",
    "        self.state_size = agent_init_info[\"state_size\"]\n",
    "        self.num_actions = agent_init_info[\"num_actions\"]\n",
    "        self.epsilon = agent_init_info[\"epsilon\"]\n",
    "        self.step_size = agent_init_info[\"step_size\"]\n",
    "        self.discount = agent_init_info[\"discount\"]\n",
    "        self.rand_generator = np.random.RandomState(agent_init_info[\"seed\"])\n",
    "        self.has_made_a_decision = False \n",
    "        self.q = {}\n",
    "        self.counter = 0\n",
    "        \n",
    "        self.state = None\n",
    "        self.next_state = None\n",
    "        self.action = None\n",
    "\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # DQN network  \n",
    "        self.dqn = NN(52, self.num_actions).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.dqn.parameters(), lr=self.step_size)\n",
    "\n",
    "        self.target_network = NN(52, self.num_actions).to(self.device).eval()\n",
    "\n",
    "        # Create memory\n",
    "        self.max_memory_size = max_memory_size\n",
    "\n",
    "        self.STATE_MEM = torch.zeros(max_memory_size, *self.state_size)\n",
    "        self.ACTION_MEM = torch.zeros(max_memory_size, 1)\n",
    "        self.REWARD_MEM = torch.zeros(max_memory_size, 1)\n",
    "        self.STATE2_MEM = torch.zeros(max_memory_size, *self.state_size)\n",
    "        self.DONE_MEM = torch.zeros(max_memory_size, 1)\n",
    "        self.ending_position = 0\n",
    "        self.num_in_queue = 0\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Learning parameters\n",
    "        self.mse_loss = nn.MSELoss().to(self.device) # Also known as Huber loss\n",
    "\n",
    "    def one_hot_encode_card(self, card):\n",
    "        encoding = [0 for i in range(52)]\n",
    "        families = {'♥':0, '♠':1, '♦':2, '♣':3}\n",
    "        values = {'A':0, '2':1, '3':2, '4':3, '5':4, '6':5, '7':6, '8':7, '9':8, 'T':9, 'J':10, 'Q':11, 'K':12}\n",
    "        val = card[:-1]\n",
    "        fam = card[-1]\n",
    "        encoding_value = 13*families[fam] + values[val]\n",
    "        encoding[encoding_value] = 1\n",
    "        return(encoding)\n",
    "\n",
    "    def remember(self, state, action, reward, state2, done):\n",
    "        \"\"\"Store the experiences in a buffer to use later\"\"\"\n",
    "        # convert to tensor\n",
    "        state = torch.Tensor(state)\n",
    "        action = torch.tensor([action])\n",
    "        state2 = torch.Tensor([state2])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([int(done)])\n",
    "\n",
    "\n",
    "        self.STATE_MEM[self.ending_position] = state.float()\n",
    "        self.ACTION_MEM[self.ending_position] = action.float()\n",
    "        self.REWARD_MEM[self.ending_position] = reward.float()\n",
    "        self.STATE2_MEM[self.ending_position] = state2.float()\n",
    "        self.DONE_MEM[self.ending_position] = done.float()\n",
    "        self.ending_position = (self.ending_position + 1) \n",
    "    \n",
    "    def batch_experiences(self):\n",
    "        \"\"\"Randomly sample 'batch size' experiences\"\"\"\n",
    "        idx = random.choices(range(self.ending_position), k = self.batch_size)\n",
    "        STATE = self.STATE_MEM[idx]\n",
    "        ACTION = self.ACTION_MEM[idx]\n",
    "        REWARD = self.REWARD_MEM[idx]\n",
    "        STATE2 = self.STATE2_MEM[idx]\n",
    "        DONE = self.DONE_MEM[idx]      \n",
    "        return STATE, ACTION, REWARD, STATE2, DONE\n",
    "    \n",
    "    def step(self, state):\n",
    "        \"\"\"Epsilon-greedy action\"\"\"\n",
    "        state = torch.Tensor(state)\n",
    "        if random.random() < self.epsilon:  \n",
    "            return torch.tensor([[random.randrange(self.num_actions)]])\n",
    "        else:\n",
    "            state = torch.unsqueeze(state, dim = 0)\n",
    "            with torch.no_grad():\n",
    "                return torch.argmax(self.dqn(state.to(self.device))).unsqueeze(0).unsqueeze(0).cpu()\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.load_state_dict(self.dqn.state_dict())\n",
    "        self.target_network.eval()\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if self.batch_size >= self.ending_position:\n",
    "            return\n",
    "        else:\n",
    "            # Sample a batch of experiences\n",
    "            STATE, ACTION, REWARD, STATE2, DONE = self.batch_experiences()\n",
    "            STATE = STATE.to(self.device)\n",
    "            ACTION = ACTION.to(self.device)\n",
    "            REWARD = REWARD.to(self.device)\n",
    "            STATE2 = STATE2.to(self.device)\n",
    "            DONE = DONE.to(self.device)\n",
    "\n",
    "            # compute target to predict\n",
    "            with torch.no_grad():\n",
    "                future_q_s = self.target_network(STATE2)\n",
    "            # next values if best action taken\n",
    "            future_discounted_rewards = self.discount*future_q_s.max(1).values\n",
    "            target = REWARD +future_discounted_rewards\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            # Q-Learning target is Q*(S, A) <- r + γ max_a Q(S', a) \n",
    "            current = self.dqn(STATE).max(1).values\n",
    "            loss = self.mse_loss(current, target)\n",
    "            print(loss)\n",
    "            loss.backward() # Compute gradients\n",
    "            self.optimizer.step() # Backpropagate error\n",
    "\n",
    "     \n",
    "    def set_epsilon(self, value):\n",
    "        self.epsilon = value\n",
    "\n",
    "\n",
    "    def act(self, info_dict):\n",
    "        reward = info_dict['rewards'][self.player_id]\n",
    "        done = info_dict['done']\n",
    "        state = info_dict['state']\n",
    "        state = np.array(self.one_hot_encode_card(str(state[0])))+np.array(self.one_hot_encode_card(str(state[1]))) # encode hand into a vector\n",
    "        number_of_chips = info_dict['stacks'][self.player_id]\n",
    "\n",
    "        if self.counter%1000 == 0:\n",
    "            # transfer weight every 100 epochs\n",
    "            self.update_target_network()\n",
    "            self.state = state\n",
    "        \n",
    "        if not self.has_made_a_decision:\n",
    "            # first decision but cannot update network yet \n",
    "            self.state = state\n",
    "            action = self.step(state)\n",
    "            self.action = action\n",
    "            self.has_made_a_decision = True\n",
    "\n",
    "        else:\n",
    "            # update state\n",
    "            self.next_state = self.state\n",
    "            self.state = state\n",
    "            # remember\n",
    "            self.remember(self.state, self.action, reward, self.next_state, done)\n",
    "\n",
    "            # train\n",
    "            if self.counter >= self.batch_size and self.counter%10 == 0:\n",
    "                # replay only if enough experiences in memory\n",
    "                self.experience_replay()\n",
    "            \n",
    "            # take new action\n",
    "            action = self.step(self.state)\n",
    "            self.action = action\n",
    "\n",
    "\n",
    "        self.counter += 1\n",
    "        if action == 0:\n",
    "            return(0)\n",
    "        else:\n",
    "            return(number_of_chips)\n",
    "\n",
    "    @staticmethod\n",
    "    def load(path):\n",
    "        obj = pickle.load(open(path,'wb'))\n",
    "        return(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3d2f41cb-0b18-4a29-96d3-76947b43d486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 68/100000 [00:00<05:10, 322.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(300.4641, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(398.2038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(14.1450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(310.1714, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(198.6781, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(202.1883, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(300.8004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(300.3970, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.4682, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.5380, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 130/100000 [00:00<06:27, 257.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(299.9745, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4511, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.6178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4293, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.6235, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(198.6043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(198.1501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3870, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 181/100000 [00:00<07:21, 225.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(198.2017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.9716, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(502.4796, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.3073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(102.1180, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(298.9879, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(299.3770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.5322, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 226/100000 [00:00<08:01, 207.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(496.2078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.6638, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(98.9490, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4981, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8311, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5962, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(197.2251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(492.0644, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 247/100000 [00:01<08:28, 196.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(295.4574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(295.0704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(103.0703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.7857, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(201.0221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(1.3459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(303.3113, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 317/100000 [00:01<07:47, 213.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(205.8686, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(98.9380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(205.3224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(298.4699, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(196.5895, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.7559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(498.5442, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(204.7260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(404.8527, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 365/100000 [00:01<07:26, 223.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(302.9038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(298.9050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5291, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(98.8665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(295.7120, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.7006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(102.3179, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(197.3203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(397.6274, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 389/100000 [00:01<07:20, 226.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(302.0239, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(299.0173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(98.8818, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(403.5492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.0597, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(102.0334, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.4414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.1401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.8276, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 434/100000 [00:01<08:02, 206.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(102.1040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(400.4806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(197.8661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.4809, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(400.5273, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(296.7357, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(398.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3947, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 477/100000 [00:02<08:05, 204.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3466, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(304.3545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.1097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(299.2178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3479, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5308, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.1496, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.5369, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.5200, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 528/100000 [00:02<07:16, 227.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(400.4715, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.5761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(300.6274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.4122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.5278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.4956, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(201.1468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6786, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 597/100000 [00:02<07:26, 222.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(300.4416, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.9313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3512, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.8000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.6966, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5453, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 643/100000 [00:02<07:21, 224.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4409, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.2784, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.6695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.0975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.0207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(299.9128, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.8936, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 666/100000 [00:02<07:27, 221.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.4251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(302.8948, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(198.6847, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(202.1817, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(303.0673, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.2994, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 741/100000 [00:03<07:02, 234.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(202.0415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(299.6083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.0294, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.8938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(301.9607, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.8620, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.4205, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 766/100000 [00:03<07:04, 233.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4933, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(199.6756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.0791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(201.2813, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(201.1487, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.7785, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2882, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.7401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(201.0995, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4695, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 842/100000 [00:03<06:51, 240.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100.3420, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.6857, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.7282, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.4476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(300.3228, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.4189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.3727, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.1510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3367, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 894/100000 [00:03<06:41, 246.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(100.0308, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(201.2341, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4136, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(299.7928, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.6753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3701, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.1652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.0982, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(201.9806, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 919/100000 [00:04<06:49, 242.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(299.5132, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(198.7451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.3993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4213, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(198.4329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.4970, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.4839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.1545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.2617, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 969/100000 [00:04<07:08, 231.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(301.5023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(301.5145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(301.4777, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3124, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(99.1038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3899, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(101.5374, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3729, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1017/100000 [00:04<07:16, 226.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(101.3683, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(301.4541, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5000, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.6225, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(300.5232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.5700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.3476, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.8150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(400.6008, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1064/100000 [00:04<07:14, 227.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(200.5746, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.6616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.5761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(100.4694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(200.6415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(300.8800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(600.9050, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1075/100000 [00:04<07:15, 227.09it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\RL\\reinforcement-learning-poker\\notebooks\\all_in_fold_deep_q.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000019?line=19'>20</a>\u001b[0m info_dict[\u001b[39m'\u001b[39m\u001b[39mstacks\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m obs[\u001b[39m'\u001b[39m\u001b[39mstacks\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000019?line=21'>22</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000019?line=22'>23</a>\u001b[0m     bet \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mact(info_dict)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000019?line=23'>24</a>\u001b[0m     obs, rewards, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(bet)  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000019?line=24'>25</a>\u001b[0m     \u001b[39m# updata dict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\RL\\reinforcement-learning-poker\\venv\\lib\\site-packages\\clubs_gym\\envs\\env.py:194\u001b[0m, in \u001b[0;36mClubsEnv.act\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/clubs_gym/envs/env.py?line=189'>190</a>\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mEnvironmentResetError(\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/clubs_gym/envs/env.py?line=190'>191</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcall reset() before calling first step()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/clubs_gym/envs/env.py?line=191'>192</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/clubs_gym/envs/env.py?line=192'>193</a>\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_obs[\u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/clubs_gym/envs/env.py?line=193'>194</a>\u001b[0m bet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magents[action]\u001b[39m.\u001b[39;49mact(obs)\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/clubs_gym/envs/env.py?line=194'>195</a>\u001b[0m \u001b[39mreturn\u001b[39;00m bet\n",
      "\u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\RL\\reinforcement-learning-poker\\notebooks\\all_in_fold_deep_q.ipynb Cell 19'\u001b[0m in \u001b[0;36mDQNAgent.act\u001b[1;34m(self, info_dict)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=153'>154</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=154'>155</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounter \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounter\u001b[39m%\u001b[39m\u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=155'>156</a>\u001b[0m     \u001b[39m# replay only if enough experiences in memory\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=156'>157</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperience_replay()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=158'>159</a>\u001b[0m \u001b[39m# take new action\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=159'>160</a>\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate)\n",
      "\u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\RL\\reinforcement-learning-poker\\notebooks\\all_in_fold_deep_q.ipynb Cell 19'\u001b[0m in \u001b[0;36mDQNAgent.experience_replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=117'>118</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmse_loss(current, target)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=118'>119</a>\u001b[0m \u001b[39mprint\u001b[39m(loss)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=119'>120</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# Compute gradients\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/notebooks/all_in_fold_deep_q.ipynb#ch0000018?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\RL\\reinforcement-learning-poker\\venv\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\33631\\Documents\\Etudes\\centrale 3A\\RL\\reinforcement-learning-poker\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/33631/Documents/Etudes/centrale%203A/RL/reinforcement-learning-poker/venv/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clubs_gym.envs.register({env_str: config_dict})\n",
    "env = gym.make(env_str)\n",
    "q_learning_agent_info = {\"state_size\":[52], \"num_actions\": 2 , \"epsilon\": 0.1, \"step_size\": 0.1, \"discount\": 1.0, \"seed\": 0}\n",
    "agents = [DQNAgent(0, q_learning_agent_info), RandomAllInFold(1)]\n",
    "env.register_agents(agents)\n",
    "rewards_list = []\n",
    "# Start the game\n",
    "for episodes in tqdm(range(100000), position = 0):\n",
    "    obs = env.reset(reset_stacks = True, reset_button = True)\n",
    "\n",
    "    # create a dict containing all necessary info for q learning agent\n",
    "    info_dict = {}\n",
    "    if obs['action'] != -1:\n",
    "        done_agent = False\n",
    "    else:\n",
    "        done_agent = True\n",
    "    info_dict['rewards'] = [0,0]\n",
    "    info_dict['done'] = done_agent\n",
    "    info_dict['state'] = obs['hole_cards']\n",
    "    info_dict['stacks'] = obs['stacks']\n",
    "\n",
    "    while True:\n",
    "        bet = env.act(info_dict)\n",
    "        obs, rewards, done, info = env.step(bet)  \n",
    "        # updata dict\n",
    "        info_dict = {}\n",
    "        if obs['action'] != -1:\n",
    "            done_agent = False\n",
    "        else:\n",
    "            done_agent = True\n",
    "        info_dict['rewards'] = rewards\n",
    "        info_dict['done'] = done_agent\n",
    "        info_dict['state'] = obs['hole_cards']\n",
    "        info_dict['stacks'] = obs['stacks']\n",
    "\n",
    "\n",
    "        # print_obs(obs)\n",
    "        if all(done):\n",
    "            agents[0].act(info_dict)\n",
    "            rewards_list.append(rewards[0])\n",
    "\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7eebcba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(rewards_list, window_size = 1000):\n",
    "    avg_list = []\n",
    "    rewards_list = np.array(rewards_list)\n",
    "    for i in range(0, len(rewards_list)-window_size, window_size):\n",
    "        avg_list.append(np.mean(rewards_list[i:i+window_size]))\n",
    "    return(avg_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1b6cd054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x277b9af9970>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(sliding_window(rewards_list, window_size = 1000))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcec69c699ccacfedc0ca836cb12e805212fde22d8796542a43a04124dd506b9"
  },
  "kernelspec": {
   "display_name": "PokerKernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
